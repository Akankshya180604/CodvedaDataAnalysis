Codveda Technologies – Data Analytics Internship Projects
This repository showcases all the completed tasks during the *Codveda Technologies Data Analytics Internship*. The work spans across three levels—basic to advanced—and demonstrates data preprocessing, exploratory analysis, visualization, regression, classification, time-series forecasting, and dashboard development using Python and visualization tools.

Datasets Utilized: 
Churn 80 Dataset  
Details: A structured dataset containing 80 customer records used for churn prediction and classification.  

Stock Market Dataset
Details: Contains daily closing values for Amazon stock retrieved using Yahoo Finance API.  

Level 1 – Basic Data Analysis Tasks
Task 1: Data Cleaning and Preprocessing
- Imported data using Pandas
- Handled null entries and removed duplicate records
- Parsed date fields 
- Standardized missing fields 
Notebook: Churn 80.ipynb

Task 2: Exploratory Data Analysis(EDA)
- Generated summary stats: mean, median, and standard deviation
- Created distribution plots with histograms and boxplots
- Evaluated correlations with a heatmap
- Explored variation in prices based on room types and location
Notebook: Churn 80 Prediction.ipynb

Task 3: Visualization and Reporting
- Developed a bar graph showing count of listings per room type
- Plotted line chart for average prices across neighborhoods
- Created a scatter plot between price and number of reviews
- Exported all visualizations as image files
Notebook: Churn 80.ipynb  
Output Files: Bar plot for total day minutes.png, Line chart for Customer service calls vs Total day minutes.png, Scatter Plot for international calls minutes vs charges.png

Level 2 – Intermediate Analytical Tasks
Task 1: Regression  Analysis
- Dataset: Churn 80
- Implemented a linear regression model with scikit-learn
- Performed train-test split and model fitting
- Analyzed model performance using R² score and Mean Squared Error
Notebook: Churn 80.ipynb

Task 2: Time Series Analysis
- Data: Stock price prediction
- Plotted historical trends using line charts
- Applied smoothing techniques like moving average
- Decomposed the time series into seasonal and trend components
Notebook: Stock Price.ipynb

Task 3:Classification Modeling
- Dataset: Churn 80
- Encoded categorical data and performed scaling
- Trained classification models including Logistic Regression and Decision Tree
- Evaluated predictions using precision, recall, F1-score, and accuracy
Notebook: Churn 80.ipynb

Level 3 – Advanced Projects
Task 1: Interactive Dashboard in Tableau
- Utilized House price prediction dataset to build a dashboard in Tableau
- Created visuals such as maps, bar charts, and time-based plots
- Enabled interactivity with filters and slicers
File: Tableau.twb

Task 2: Sentiment Analysis (NLP)
- Dataset: Sample Twitter data
- Text cleaning: stopword removal, tokenization, and lemmatization
- Sentiment polarity calculated using TextBlob
- Visualized results with word clouds and sentiment pie charts
Notebook: sentiment.ipynb

Task 3 : Predictive Analysis
- Built and evaluated ML models (Logistic Regression, Random Forest, Gradient Boosting)
- Tuned hyperparameters using GridSearchCV
- Visualized model performance using accuracy scores and ROC curves
Notebook: Churn 80.ipynb


Tools and Libraries Used
- Python 
- pandas, numpy
- matplotlib, seaborn
- scikit-learn, statsmodels
- nltk, textblob
- Jupyter Notebook for development
- Tableau for dashboard visualization

